{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ac153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import collections\n",
    "import shutil\n",
    "import ssl \n",
    "import copy\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "import albumentations as A\n",
    "import cv2 as cv \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from PIL import Image\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset,DataLoader,random_split,Subset\n",
    "from torchvision import datasets,models,transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "ssl._create_default_https_context = ssl._create_unverified_context \n",
    "import PIL           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc25566",
   "metadata": {},
   "source": [
    "**Background** :Australia's stunningly beautiful Great Barrier Reef is under threat because of the overpopulation of one particular starfish â€“ the coral-eating crown-of-thorns starfish.Scientists, tourism operators and reef managers established a large-scale intervention program to control COTS outbreaks to ecologically sustainable levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49ea91",
   "metadata": {},
   "source": [
    "**Objective** :Accurately identify starfish in real-time by building an object detection model trained on underwater videos of coral reefs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7653204",
   "metadata": {},
   "source": [
    "**Type** :Object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b520531",
   "metadata": {},
   "source": [
    "**Scale**: 4919"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27c9b6",
   "metadata": {},
   "source": [
    "**Evaluation**: F2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58614ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7339d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524c759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/wangshuo/Documents/data/tensorflow-great-barrier-reef/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3899129e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# images\n",
    "folders = [path/'train_images'/'video_0', path/'train_images'/'video_1', path/'train_images'/'video_2']\n",
    "dest_folder = path/'images'\n",
    "\n",
    "for folder in folders:\n",
    "    prefix = str(folder)[-1] + '-'\n",
    "    for file in os.listdir(folder):\n",
    "        old_file = os.path.join(folder, file)\n",
    "        new_file = os.path.join(folder, prefix + file)\n",
    "        os.rename(old_file, new_file)\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(folder):\n",
    "        src = os.path.join(folder, file)\n",
    "        shutil.copy(src, dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8730b0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "train_transform = A.Compose([\n",
    "    A.Flip(0.5),\n",
    "    ToTensorV2()\n",
    "], bbox_params = {'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    ToTensorV2(),\n",
    "], bbox_params = {'format': 'pascal_voc', 'label_fields': ['labels']}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8013e5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# data\n",
    "# df \n",
    "train = pd.read_csv(path/'train.csv')\n",
    "\n",
    "train = train[train.annotations != '[]'].reset_index(drop=True)\n",
    "\n",
    "x, y, w, h = [], [], [], []\n",
    "for a, b in enumerate(train.annotations):\n",
    "    boxes_list = json.loads(b.replace(\"'\", '\"'))\n",
    "    _x, _y, _w, _h = [], [], [], []\n",
    "    for box in boxes_list:\n",
    "        _x.append(box['x'])\n",
    "        _y.append(box['y'])\n",
    "        _w.append(box['width'])\n",
    "        _h.append(box['height'])\n",
    "    x.append(_x)\n",
    "    y.append(_y)\n",
    "    w.append(_w)\n",
    "    h.append(_h) \n",
    "train['x'] = x\n",
    "train['y'] = y\n",
    "train['w'] = w\n",
    "train['h'] = h\n",
    "\n",
    "def xmax(df):\n",
    "    return [x + y for x, y in zip(df.x, df.w)]\n",
    "def ymax(df):\n",
    "    return [x + y for x, y in zip(df.y, df.h)]\n",
    "def k(df):\n",
    "    return sum(np.array(df.xmax)>1280) + sum(np.array(df.ymax)>720)\n",
    "\n",
    "train['xmax'] = train.apply(xmax,axis=1)\n",
    "train['ymax'] = train.apply(ymax,axis=1)\n",
    "train['valid_boxes'] = train.apply(k,axis=1)\n",
    "\n",
    "train = train[~(train.valid_boxes>0)].reset_index(drop=True)\n",
    "\n",
    "train, test = train_test_split(train, test_size=0.25)\n",
    "\n",
    "# dataset\n",
    "class StarfishDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, img_dir, transform):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.img_ids = df.image_id\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_id = self.df.iloc[index]['image_id']\n",
    "        d = self.df[self.df['image_id'] == img_id] \n",
    "        \n",
    "        image = cv2.imread(f'{self.img_dir}/{img_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        b = d[['x', 'y', 'w', 'h']].values\n",
    "        boxes = []\n",
    "        for i in range(len(b[0][0])):\n",
    "            boxes.append([[box[0][i], box[1][i], box[2][i]+box[0][i], box[3][i]+box[1][i]] for box in b][0])\n",
    "        \n",
    "        area =[(x[2]-x[0])*(x[3]-x[1]) for x in boxes]\n",
    "        area = torch.tensor(area)\n",
    "        \n",
    "        labels = torch.ones((torch.tensor(boxes).shape[0],),dtype=torch.int64)\n",
    "        \n",
    "        iscrowd = torch.zeros(torch.tensor(boxes).shape[0]) \n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['img_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        \n",
    "        p = {'image': image, 'bboxes': boxes, 'labels': labels}\n",
    "        res = self.transform(**p)\n",
    "        image = res['image']\n",
    "        target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*res['bboxes'])))).permute(1, 0)\n",
    "        target['boxes'] = target['boxes'].to(torch.float32)\n",
    "        return image, target, img_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.img_ids.shape[0] \n",
    "\n",
    "train_data = StarfishDataset(df=train,img_dir=path/'images',transform=train_transform)\n",
    "test_data = StarfishDataset(df=test,img_dir=path/'images',transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=8,shuffle=True,collate_fn=lambda batch: tuple(zip(*batch))) \n",
    "test_loader = DataLoader(test_data,batch_size=8,shuffle=True,collate_fn=lambda batch: tuple(zip(*batch)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad0d3b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# sampel\n",
    "images, targets, img_ids = next(iter(train_loader))\n",
    "boxes = targets[2]['boxes'].cpu().numpy().astype(np.int32)\n",
    "img = images[2].permute(1,2,0).cpu().numpy() \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "for box in boxes:\n",
    "    cv2.rectangle(img,\n",
    "                  (box[0], box[1]),\n",
    "                  (box[2], box[3]),\n",
    "                  (255, 0, 255), 2)\n",
    "    \n",
    "ax.set_axis_off()\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8224cc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=models.detection.faster_rcnn.FasterRCNN_ResNet50_FPN_Weights.DEFAULT,\n",
    "    rpn_pre_nms_top_n_train=16)\n",
    "\n",
    "    \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)  \n",
    "\n",
    "# train\n",
    "model.to('mps')\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57001598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e7f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model([train_data[0][0]],[train_data[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model([train_data[0][0].to('mps')],[{k: v.to('mps') for k, v in train_data[0][1].items()}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544dc23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, targets, img_ids in tqdm(train_loader):\n",
    "    imgs = list(img.to('mps') for img in imgs)\n",
    "    targets = [{k: v.to('mps') for k, v in t.items()} for t in targets]\n",
    "    loss_dic = model(imgs,targets)\n",
    "    loss = sum(loss for loss in loss_dic.values())\n",
    "    \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc12144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af2fe9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# git\n",
    "!git init\n",
    "\n",
    "!git remote -v\n",
    "\n",
    "!git remote set-url origin \"https://github.com/0731ws/portfolio.git/tensorflow-great-barrier-reef\"\n",
    "\n",
    "!git remote add origin https://github.com/0731ws/portfolio.git  \n",
    "\n",
    "!git add \"starfish.ipynb\"\n",
    "\n",
    "!git commit -m \"Initial commit\"\n",
    "\n",
    "!git commit -m \"Upload notebook to folder\"\n",
    "\n",
    "!git push -u origin master\n",
    "\n",
    "!git config --global user.name \"WangShuo\"\n",
    "\n",
    "!git config --global user.email \"ws13127789446@163.com\"\n",
    "\n",
    "!git push -u origin main\n",
    "\n",
    "!git pull origin main\n",
    "\n",
    "!git config --global http.version HTTP/1.1\n",
    "\n",
    "!git pull --rebase origin main\n",
    "\n",
    "git config --global --unset http.proxy\n",
    "git config --global --unset https.proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "git stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "git ls-files -c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "git branch -D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36722c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "git rm --cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c650f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "git ls-files --stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "git push origin --delete dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "git reset HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "git reset --soft HEAD^ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "git push origin main -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "git rm -r --cached <folder_name>\n",
    "git commit -m \"Removed folder <folder_name> from remote repository\"\n",
    "git push origin <branch_name>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
